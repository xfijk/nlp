{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducation:\n",
    "    This homework is started by reading the baseline algorithm given by the professor. Implementing the baseline algorithm and then started to read the fifth paper.  Because the third paper is more related to the basic search algorithm, the improvement from the method in the third paper. After finished the paper three improvement, starting to improve the algorithm using the method in the fifth paper.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search Algorithm with ngram LM:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline is finshed by following the homework 2 description and the 1st and 2nd paper.   \n",
    "\n",
    "Firstly, writing the basic of it, then adding other components in the order of score(), prune(), ext_limits().\n",
    "( for winner(), we just use prune() )\n",
    "\n",
    "\n",
    "For the score(), using score_seq() and score_bitstring() from ngram.py to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The third paper:\n",
    "    Calculating sum weight of n-order continous context during our decipherment. This is aim for improving our beam search algorithm in terms of speed. Counting the number of maximum content for each n-gram and sum them up with the weight [1,1,1,1,4,5]. Using that score to decide which cipher symbol to decipher next. However, the result does not seem to have much effect.\n",
    "    Trying to assign different ext_limit for each letter by the frequency of each letter in the default lm. The improvement is also no effect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    At the very beginning, thinking the NLM could be used directly by calling the function Score_first() and Score_next() because difficult understanding the algorithm described in the paper. Our initial understanding is that scanning cipher from left to right. \n",
    "    When implementing the algorithm in the fifth paper, finding that our initial understanding was wrong. The paper suggested that use partial hypothesis to decipher in each iteration, which produces a partial decipherment. And using that decipherment and current partial hypothesis to sample in current context. Basically generating sample from left to right. Then implementing the score functin as described in the fifth paper that substracts FMH\n",
    "    The difficulties we met are:\n",
    "        1. Did not understand the algorithm well,  so do not understand why having FMH and what's the parameter of FMH\n",
    "        2. When ciphering the Zodiac-408, llh_predict sometimes gives us punctuations or even spaces, but our assumption is that llg_predict will always return a lowercase letter.\n",
    "        3. It takes too long to cipher, which makes it harder to try different experiment.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine differen approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tring to use nlm score function at the last loop of the beam search algorithm. However, there is almost no effect to the result.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is our implementation of beam search with n-gram\n",
    "    (Also having a version of NLM implementation in test_victor.py, but it takes too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading language model from data/6-gram-wiki-char.lm.bz2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXT_ORDER: ('—', 'º', 'B', 'R', '∫', 'P', 'I', 'u', '≈', 'y', '∑', 'À', 'X', 'W', 'V', 'E', 'Z', '+', '∞', 'H', 'M', 'µ', '£', 'A', 'L', 'æ', '∏', 'O', '•', 'G', 'T', '‘', '“', '/', '–', 'F', 'π', 'J', '^', 'N', 'D', 'S', 'ƒ', '√', 'K', 'Ç', 'Q', 'Ã', '\\\\', '¢', '§', 'Ω', '∆', 'j')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a13854b27864627b21c0f808596ef98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: -642.8312139635002\n",
      "(('e', '—'), ('a', 'º'), ('n', 'B'),\n",
      " ('e', 'R'), ('t', '∫'), ('t', 'P'),\n",
      " ('e', 'I'), ('r', 'u'), ('a', '≈'),\n",
      " ('r', 'y'), ('i', '∑'), ('a', 'À'),\n",
      " ('t', 'X'), ('n', 'W'), ('o', 'V'),\n",
      " ('r', 'E'), ('h', 'Z'), ('s', '+'),\n",
      " ('n', '∞'), ('i', 'H'), ('c', 'M'),\n",
      " ('s', 'µ'), ('s', '£'), ('i', 'A'),\n",
      " ('o', 'L'), ('l', 'æ'), ('d', '∏'),\n",
      " ('h', 'O'), ('c', '•'), ('u', 'G'),\n",
      " ('u', 'T'), ('g', '‘'), ('h', '“'),\n",
      " ('o', '/'), ('d', '–'), ('l', 'F'),\n",
      " ('u', 'π'), ('d', 'J'), ('g', '^'),\n",
      " ('w', 'N'), ('m', 'D'), ('m', 'S'),\n",
      " ('b', 'ƒ'), ('c', '√'), ('m', 'K'),\n",
      " ('l', 'Ç'), ('y', 'Q'), ('k', 'Ã'),\n",
      " ('y', '\\\\'), ('j', '¢'), ('g', '§'),\n",
      " ('v', 'Ω'), ('k', '∆'), ('q', 'j'))\n",
      "attohorntahecdtcnnosaurlnaitumleracdrgreaveugwyrmssmjoaintheirtkekeragochdbhydlionalruseumamesnetlsgmjewgerrkhleunuyminobotinutericrgeeachmedesnellsochaintmesqcnywjarrialhcdhonessgoskgenieamedurhybaoutdyitsclergtoswormicuheldasalockwishjtgrdaiainonysoughtgcmhkkranvmguttecwasmcroatthkitinodatenedlilcsuaianthusercsdbredgmenohaurmrduriatiogdillntagtimbyvolcedabiinasthetyltuchudugedldeshntynnorthanenericscrea\n"
     ]
    }
   ],
   "source": [
    "#====================================================\n",
    "# test.py\n",
    "#====================================================\n",
    "# import operator # tag2vocab()\n",
    "# import re # countRules()\n",
    "from auxilaryFunc import *\n",
    "from ngram import * \n",
    "from nlm import * \n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from collections import Counter\n",
    "import math # ceil()\n",
    "import pprint # pprint()\n",
    "pp = pprint.PrettyPrinter(width=45, compact=True)\n",
    "\n",
    "# =============================================\n",
    "# hypo -> dict \n",
    "# \t\tfind max score(dict) -> decipher\n",
    "\n",
    "\n",
    "def sum_of_weight(cipher, weight, taken, cur):\n",
    "    seq = ''\n",
    "    taken.append(cur)\n",
    "    for l in cipher:\n",
    "        seq += ' ' if l not in taken else 'o'\n",
    "\n",
    "    words = seq.split()\n",
    "    list_ngram = {}\n",
    "    for w in words:\n",
    "        if len(w) not in list_ngram:\n",
    "            list_ngram[len(w)] = 1\n",
    "        else:\n",
    "            list_ngram[len(w)] += 1\n",
    "    score = 0\n",
    "    for k in list_ngram:\n",
    "        w = weight[k-1] if k <= 6 else weight[-1]\n",
    "        score += w*list_ngram[k]\n",
    "    return  score\n",
    "\n",
    "\n",
    "# ext_order by frequency\n",
    "def getExtOrd(cipher):\n",
    "\tfreq = sorted(Counter(cipher).items(), key=lambda k:k[1], reverse=True)\n",
    "\treturn tuple([ x[0] for x in freq ])\n",
    "\n",
    "\n",
    "# get mask\n",
    "def seq2bitstring(seq):\n",
    "\tbitstring = ''\n",
    "\tfor i in seq:\n",
    "\t\tbitstring += 'o' if i != '_' else '.'\n",
    "\treturn bitstring \n",
    "\n",
    "# convert hypo to dict\n",
    "def readHypo(h):  \n",
    "\tdict = {}\n",
    "\tfor rule in h:\n",
    "\t\tdict[rule[1]]= rule[0]\n",
    "\treturn dict\n",
    "\n",
    "# get winner\n",
    "def decipher(cipher, dict):\n",
    "\tdecipher = ''\n",
    "\tfor l in cipher:\n",
    "\t\tdecipher += '' if l not in dict else dict[l]\n",
    "\treturn decipher\n",
    "\n",
    "# compute score with dict & cipher\n",
    "def score(cipher, dict, nlm=False):\n",
    "\tseq = ''\n",
    "\tfor l in cipher:\n",
    "\t\tseq += '_' if l not in dict else dict[l]\n",
    "\n",
    "\tif nlm == True: \n",
    "\t\treturn score_sequence(seq, nLM, cuda=True)\n",
    "\telse:\n",
    "\t\treturn lm.score_bitstring(seq, seq2bitstring(seq)) #- FMH('B','BURGER','b',plaintext)\n",
    "\n",
    "def score_nlm(cipher, dict):\n",
    "\tseq = ''\n",
    "\tfor l in cipher:\n",
    "\t\tseq += '\\t' if l not in dict else dict[l]\n",
    "\t# print(seq)\n",
    "\n",
    "def hypo2score(cipher, h, nlm=False):\n",
    "\treturn score(cipher, readHypo(h), nlm)\n",
    "\n",
    "def checkLimit(h, ext_limits):\n",
    "\tletters = list(map( lambda x : x[0], h))\n",
    "\tdict = {}\n",
    "\tfor k in letters:\n",
    "\t\tif k not in dict:\n",
    "\t\t    dict[k] = 1\n",
    "\t\telse:\n",
    "\t\t    dict[k] += 1\n",
    "\t\t    if dict[k] > ext_limits:\n",
    "\t\t    \treturn False\n",
    "\treturn True\n",
    "\n",
    "def checkLimit_arr(h, ext_limits):\n",
    "\tletters = list(map( lambda x : x[0], h))\n",
    "\tdict = {}\n",
    "\tfor k in letters:\n",
    "\t\tif k not in dict:\n",
    "\t\t    dict[k] = 1\n",
    "\t\telse:\n",
    "\t\t    dict[k] += 1\n",
    "\t\t    if dict[k] > ext_limits[k]:\n",
    "\t\t    \treturn False\n",
    "\treturn True\n",
    "\n",
    "def get_ext_limit_arr(length, letter, freq_perc):\n",
    "\tdict = {}\n",
    "\n",
    "\tfor l, p in zip(letter, freq_perc):\n",
    "\t\tdict[l] = (p+1)*length\n",
    "\treturn dict\n",
    "\n",
    "# get score of all hypos\n",
    "def sortScoreTable(cipher, hypos, nlm=False):\n",
    "\tscore_table = []\n",
    "\n",
    "\tif nlm == False:\n",
    "\t\tfor i in range(len(hypos)):\n",
    "\t\t\tscore_table.append([ hypo2score(cipher, hypos[i], nlm), hypos[i] ]) \n",
    "\telse:\n",
    "\t\tfor i in tqdm(range(len(hypos))):\n",
    "\t\t\tscore_table.append([ hypo2score(cipher, hypos[i], nlm), hypos[i] ]) \n",
    "\n",
    "\treturn sorted(score_table, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# prune sorted score by beam_size\n",
    "def prune(cipher, hypos, beam_size, nlm=False):\n",
    "\tsorted_table = sortScoreTable(cipher, hypos, nlm)\n",
    "\tprune_size = beam_size if beam_size < len(sorted_table) else len(sorted_table)\n",
    "\treturn tuple([ x[1] for x in sorted_table[:prune_size] ]), sorted_table[0][0]\n",
    "\n",
    "\n",
    "def checkAnswer(filename, dec): \n",
    "\t# gold_file = \"data/_ref.txt\"\n",
    "\tgold_file = filename\n",
    "\tser = symbol_error_rate(dec, gold_file)\n",
    "\tprint('Error: ', ser*100, 'Accuracy: ', (1-ser)*100)\n",
    "\n",
    "def beamSearch(cipher, beam_size, ext_limits, answer, nlm=False):\n",
    "\tletter = ('a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
    "\t\t\t 'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
    "\t\t\t  'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "\t\t\t   'v', 'w', 'x', 'y', 'z')\n",
    "\n",
    "\n",
    "\tcipher_clean = ''.join(cipher.replace('\\n', '').split())\n",
    "\text_ord = getExtOrd(cipher_clean)\n",
    "\tprint('EXT_ORDER:', ext_ord)\n",
    "\n",
    "\tif ext_limits != 0:\n",
    "\t\tmin_limit = math.ceil(len(ext_ord) / len(letter))\n",
    "\t\tif ext_limits < min_limit: ext_limits = min_limit\n",
    "\t\n",
    "\n",
    "\tfreq_perc = [0.05714285714285714, 0.02857142857142857, 0.02857142857142857, \n",
    "    0.02857142857142857, 0.11428571428571428, 0.02857142857142857, 0.02857142857142857, \n",
    "    0.02857142857142857, 0.05714285714285714, 0.02857142857142857, 0.02857142857142857, \n",
    "    0.02857142857142857, 0.02857142857142857, 0.05714285714285714, 0.05714285714285714, \n",
    "    0.02857142857142857, 0.02857142857142857, 0.02857142857142857, 0.05714285714285714, \n",
    "    0.05714285714285714, 0.02857142857142857, 0.02857142857142857, 0.02857142857142857, \n",
    "    0.02857142857142857, 0.02857142857142857, 0.02857142857142857]\n",
    "# \text_limits_arr = {'e': 7, 'a': 5, 'i': 4, 'n': 4,\n",
    "# \t 'o': 4, 't': 4, 'l': 3, 's': 3, 'r': 3, 'h': 2,\n",
    "# \t  'f': 2, 'd': 2, 'k': 1, 'g': 1, 'p': 1, 'b': 1,\n",
    "# \t   'c': 1, 'u': 1, 'm': 1, 'w': 1, 'v': 1, 'x': 1, 'y': 1}\n",
    "\n",
    "\tlength = len(ext_ord)\n",
    "\text_limits_arr = get_ext_limit_arr(length, letter, freq_perc)\n",
    "\n",
    "\ths, ht = ((),) , []\n",
    "\n",
    "\t# --------------------------------\n",
    "\t#\t\n",
    "\t# ext_ord = list(ext_ord)\n",
    "\t# taken = []\n",
    "\t# weight_matrix = [1,1,1,1,4,5]\n",
    "\t# --------------------------------\t\n",
    "\n",
    "\tfor card in tqdm(range(length)):\n",
    "\n",
    "\t# --------------------------------\t\n",
    "\t#\n",
    "\t\t# f = ext_ord[0] #if len(ext_ord) >1 else ext_ord[0] \n",
    "\t\t# taken.append(f)\n",
    "\t\t# ext_ord.remove(f)\n",
    "\n",
    "\t# --------------------------------\t\n",
    "\t\t\n",
    "\t\tf = ext_ord[card]\n",
    "\t# --------------------------------\t\n",
    "\t\tfor h in hs: \n",
    "\t\t\tfor e in letter:\n",
    "\t\t\t\tif h == ():\n",
    "\t\t\t\t\tht.append((( e, f ),)) \n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\th_ = h + (( e, f ),)\n",
    "\t\t\t\t\tif ext_limits != 0:\n",
    "\t\t\t\t\t\tif not checkLimit(h_, ext_limits):\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif not checkLimit_arr(h_, ext_limits_arr):\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\tht.append( h_ ) \n",
    "\t\ths, _ = prune(cipher_clean, ht, beam_size)\n",
    "\t\tht = []\n",
    "\t\t# print(hs)\n",
    "\n",
    "\t# --------------------------------\t\n",
    "\t#\n",
    "\t\t# current_sum = 0\n",
    "\t\t# sum_max = 0\n",
    "\t\t# for c in ext_ord:\n",
    "\t\t# \tcurrent_sum = sum_of_weight(cipher, weight_matrix, taken, c)\n",
    "\t\t# \tif current_sum >= sum_max:\n",
    "\t\t# \t\tf = c\n",
    "\t\t# \t\tsum_max = current_sum\n",
    "\t# --------------------------------\t\n",
    "\n",
    "\ths, score = prune(cipher_clean, hs, beam_size, nlm)\n",
    "\n",
    "\tprint('score:',score)\n",
    "\tpp.pprint(hs[0])\n",
    "\tdict = readHypo(hs[0])\n",
    "\tdec = decipher(cipher, dict)\n",
    "\tprint(dec)\n",
    "\t#checkAnswer(answer, dec)\n",
    "\n",
    "# =============================================\n",
    "# main\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tlm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=False)\n",
    "\n",
    "\t# cipher = 'INTERNATIONALSTUDENTSOCIETY'\n",
    "\tcipher = 'F7EZ5F UC2'\n",
    "\tcipher = 'efgfoe uif fbtu xbmm pg uif dbtumf'\n",
    "\tcipher = 'F7EZ5F UC2 1DR6 M9PP 0E 6CZ SD4UP1'\n",
    "\t# cipher = 'RIHILKHIERSKILEKKLKTRSKHRIHILKHLREIRTRSKLKTRSKHHLEKRS'\n",
    "\tcipher = read_file(\"data/cipher.txt\")\n",
    "\n",
    "\tanswer = 'data/_ref.txt'\n",
    "\t# answer = 'data/answer.txt'\n",
    "\t\n",
    "\text_limits = 1 # 0 for using limit_arr\n",
    "\tbeam_size = 3000\n",
    "\tnlm = False\n",
    "\text_ord_dynamic = True\n",
    "\n",
    "\tif nlm: \n",
    "\t\tnLM = load_model(\"data/mlstm_ns.pt\", cuda=True)\n",
    "\tbeamSearch(cipher, beam_size, ext_limits, answer, nlm)\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# =============================================\n",
    "# ============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

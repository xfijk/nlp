{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducation:\n",
    "    This homework is based on the baseline algorithm given by our professor. Implementing the baseline algorithm and then reading the fifth paper. Because the third paper is more related to the basic search algorithm, the improvable method is from the third paper. After the improvement from the third paper, improving with the method from the fifth paper.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search Algorithm with ngram LM:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline is finshed by homework 2 description, the 1st, and 2nd paper.   \n",
    "\n",
    "Firstly, writing the basic of it, then adding other components in the order of score(), prune(), ext_limits().\n",
    "( for winner(), just using prune() )\n",
    "\n",
    "\n",
    "For the score(), using score_seq() and score_bitstring() from ngram.py to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The third paper:\n",
    "    Calculating sum weight of n-order continous context during the decipherment. Improving the speed of beam search algorithm. Counting the number of maximal contents for each n-gram and summing them up with the weight [1,1,1,1,4,5]. Determining the cipher symbol for next based on the score. However, the result does not affect much.\n",
    "    Assigning different ext_limit for each letter by the frequency of each letter in the default lm. No improvement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Thinking the NLM used directly by calling the function Score_first() and Score_next() because of difficult understanding the algorithm described in the paper. Our initial understanding is scanning cipher from left to right. \n",
    "    When implementing the algorithm in the fifth paper, our initial understanding was wrong. The paper suggested that partial hypothesis to decipher in each iteration, which produces a partial decipherment. Using the partial decipherment and current partial hypothesis to sample in current context. Generating sample from left to right. The score function in the fifth paper that substracts FMH\n",
    "    The difficulties met are:\n",
    "        1. Did not understand the algorithm well,  so do not understand why using FMH and what's the parameter of FMH\n",
    "        2. When ciphering the Zodiac-408, llh_predict prints punctuations or even spaces, but our assumption is returnning a lowercase letter.\n",
    "        3. Long time ciphering makes difficult for different experiments.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine differen approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using nlm score function at the last loop of the beam search algorithm. There is a little effects to the result.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is our implementation of beam search with n-gram\n",
    "    (Also having a version of NLM implementation in test_victor.py, but it takes too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading language model from data/6-gram-wiki-char.lm.bz2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXT_ORDER: ('—', 'º', 'B', 'R', '∫', 'P', 'I', 'u', '≈', 'y', '∑', 'À', 'X', 'W', 'V', 'E', 'Z', '+', '∞', 'H', 'M', 'µ', '£', 'A', 'L', 'æ', '∏', 'O', '•', 'G', 'T', '‘', '“', '/', '–', 'F', 'π', 'J', '^', 'N', 'D', 'S', 'ƒ', '√', 'K', 'Ç', 'Q', 'Ã', '\\\\', '¢', '§', 'Ω', '∆', 'j')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a13854b27864627b21c0f808596ef98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score: -642.8312139635002\n",
      "(('e', '—'), ('a', 'º'), ('n', 'B'),\n",
      " ('e', 'R'), ('t', '∫'), ('t', 'P'),\n",
      " ('e', 'I'), ('r', 'u'), ('a', '≈'),\n",
      " ('r', 'y'), ('i', '∑'), ('a', 'À'),\n",
      " ('t', 'X'), ('n', 'W'), ('o', 'V'),\n",
      " ('r', 'E'), ('h', 'Z'), ('s', '+'),\n",
      " ('n', '∞'), ('i', 'H'), ('c', 'M'),\n",
      " ('s', 'µ'), ('s', '£'), ('i', 'A'),\n",
      " ('o', 'L'), ('l', 'æ'), ('d', '∏'),\n",
      " ('h', 'O'), ('c', '•'), ('u', 'G'),\n",
      " ('u', 'T'), ('g', '‘'), ('h', '“'),\n",
      " ('o', '/'), ('d', '–'), ('l', 'F'),\n",
      " ('u', 'π'), ('d', 'J'), ('g', '^'),\n",
      " ('w', 'N'), ('m', 'D'), ('m', 'S'),\n",
      " ('b', 'ƒ'), ('c', '√'), ('m', 'K'),\n",
      " ('l', 'Ç'), ('y', 'Q'), ('k', 'Ã'),\n",
      " ('y', '\\\\'), ('j', '¢'), ('g', '§'),\n",
      " ('v', 'Ω'), ('k', '∆'), ('q', 'j'))\n",
      "attohorntahecdtcnnosaurlnaitumleracdrgreaveugwyrmssmjoaintheirtkekeragochdbhydlionalruseumamesnetlsgmjewgerrkhleunuyminobotinutericrgeeachmedesnellsochaintmesqcnywjarrialhcdhonessgoskgenieamedurhybaoutdyitsclergtoswormicuheldasalockwishjtgrdaiainonysoughtgcmhkkranvmguttecwasmcroatthkitinodatenedlilcsuaianthusercsdbredgmenohaurmrduriatiogdillntagtimbyvolcedabiinasthetyltuchudugedldeshntynnorthanenericscrea\n"
     ]
    }
   ],
   "source": [
    "#====================================================\n",
    "# test.py\n",
    "#====================================================\n",
    "# import operator # tag2vocab()\n",
    "# import re # countRules()\n",
    "from auxilaryFunc import *\n",
    "from ngram import * \n",
    "from nlm import * \n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from collections import Counter\n",
    "import math # ceil()\n",
    "import pprint # pprint()\n",
    "pp = pprint.PrettyPrinter(width=45, compact=True)\n",
    "\n",
    "# =============================================\n",
    "# hypo -> dict \n",
    "# \t\tfind max score(dict) -> decipher\n",
    "\n",
    "\n",
    "def sum_of_weight(cipher, weight, taken, cur):\n",
    "    seq = ''\n",
    "    taken.append(cur)\n",
    "    for l in cipher:\n",
    "        seq += ' ' if l not in taken else 'o'\n",
    "\n",
    "    words = seq.split()\n",
    "    list_ngram = {}\n",
    "    for w in words:\n",
    "        if len(w) not in list_ngram:\n",
    "            list_ngram[len(w)] = 1\n",
    "        else:\n",
    "            list_ngram[len(w)] += 1\n",
    "    score = 0\n",
    "    for k in list_ngram:\n",
    "        w = weight[k-1] if k <= 6 else weight[-1]\n",
    "        score += w*list_ngram[k]\n",
    "    return  score\n",
    "\n",
    "\n",
    "# ext_order by frequency\n",
    "def getExtOrd(cipher):\n",
    "\tfreq = sorted(Counter(cipher).items(), key=lambda k:k[1], reverse=True)\n",
    "\treturn tuple([ x[0] for x in freq ])\n",
    "\n",
    "\n",
    "# get mask\n",
    "def seq2bitstring(seq):\n",
    "\tbitstring = ''\n",
    "\tfor i in seq:\n",
    "\t\tbitstring += 'o' if i != '_' else '.'\n",
    "\treturn bitstring \n",
    "\n",
    "# convert hypo to dict\n",
    "def readHypo(h):  \n",
    "\tdict = {}\n",
    "\tfor rule in h:\n",
    "\t\tdict[rule[1]]= rule[0]\n",
    "\treturn dict\n",
    "\n",
    "# get winner\n",
    "def decipher(cipher, dict):\n",
    "\tdecipher = ''\n",
    "\tfor l in cipher:\n",
    "\t\tdecipher += '' if l not in dict else dict[l]\n",
    "\treturn decipher\n",
    "\n",
    "# compute score with dict & cipher\n",
    "def score(cipher, dict, nlm=False):\n",
    "\tseq = ''\n",
    "\tfor l in cipher:\n",
    "\t\tseq += '_' if l not in dict else dict[l]\n",
    "\n",
    "\tif nlm == True: \n",
    "\t\treturn score_sequence(seq, nLM, cuda=True)\n",
    "\telse:\n",
    "\t\treturn lm.score_bitstring(seq, seq2bitstring(seq)) #- FMH('B','BURGER','b',plaintext)\n",
    "\n",
    "def score_nlm(cipher, dict):\n",
    "\tseq = ''\n",
    "\tfor l in cipher:\n",
    "\t\tseq += '\\t' if l not in dict else dict[l]\n",
    "\t# print(seq)\n",
    "\n",
    "def hypo2score(cipher, h, nlm=False):\n",
    "\treturn score(cipher, readHypo(h), nlm)\n",
    "\n",
    "def checkLimit(h, ext_limits):\n",
    "\tletters = list(map( lambda x : x[0], h))\n",
    "\tdict = {}\n",
    "\tfor k in letters:\n",
    "\t\tif k not in dict:\n",
    "\t\t    dict[k] = 1\n",
    "\t\telse:\n",
    "\t\t    dict[k] += 1\n",
    "\t\t    if dict[k] > ext_limits:\n",
    "\t\t    \treturn False\n",
    "\treturn True\n",
    "\n",
    "def checkLimit_arr(h, ext_limits):\n",
    "\tletters = list(map( lambda x : x[0], h))\n",
    "\tdict = {}\n",
    "\tfor k in letters:\n",
    "\t\tif k not in dict:\n",
    "\t\t    dict[k] = 1\n",
    "\t\telse:\n",
    "\t\t    dict[k] += 1\n",
    "\t\t    if dict[k] > ext_limits[k]:\n",
    "\t\t    \treturn False\n",
    "\treturn True\n",
    "\n",
    "def get_ext_limit_arr(length, letter, freq_perc):\n",
    "\tdict = {}\n",
    "\n",
    "\tfor l, p in zip(letter, freq_perc):\n",
    "\t\tdict[l] = (p+1)*length\n",
    "\treturn dict\n",
    "\n",
    "# get score of all hypos\n",
    "def sortScoreTable(cipher, hypos, nlm=False):\n",
    "\tscore_table = []\n",
    "\n",
    "\tif nlm == False:\n",
    "\t\tfor i in range(len(hypos)):\n",
    "\t\t\tscore_table.append([ hypo2score(cipher, hypos[i], nlm), hypos[i] ]) \n",
    "\telse:\n",
    "\t\tfor i in tqdm(range(len(hypos))):\n",
    "\t\t\tscore_table.append([ hypo2score(cipher, hypos[i], nlm), hypos[i] ]) \n",
    "\n",
    "\treturn sorted(score_table, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# prune sorted score by beam_size\n",
    "def prune(cipher, hypos, beam_size, nlm=False):\n",
    "\tsorted_table = sortScoreTable(cipher, hypos, nlm)\n",
    "\tprune_size = beam_size if beam_size < len(sorted_table) else len(sorted_table)\n",
    "\treturn tuple([ x[1] for x in sorted_table[:prune_size] ]), sorted_table[0][0]\n",
    "\n",
    "\n",
    "def checkAnswer(filename, dec): \n",
    "\t# gold_file = \"data/_ref.txt\"\n",
    "\tgold_file = filename\n",
    "\tser = symbol_error_rate(dec, gold_file)\n",
    "\tprint('Error: ', ser*100, 'Accuracy: ', (1-ser)*100)\n",
    "\n",
    "def beamSearch(cipher, beam_size, ext_limits, answer, nlm=False):\n",
    "\tletter = ('a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
    "\t\t\t 'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
    "\t\t\t  'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "\t\t\t   'v', 'w', 'x', 'y', 'z')\n",
    "\n",
    "\n",
    "\tcipher_clean = ''.join(cipher.replace('\\n', '').split())\n",
    "\text_ord = getExtOrd(cipher_clean)\n",
    "\tprint('EXT_ORDER:', ext_ord)\n",
    "\n",
    "\tif ext_limits != 0:\n",
    "\t\tmin_limit = math.ceil(len(ext_ord) / len(letter))\n",
    "\t\tif ext_limits < min_limit: ext_limits = min_limit\n",
    "\t\n",
    "\n",
    "\tfreq_perc = [0.05714285714285714, 0.02857142857142857, 0.02857142857142857, \n",
    "    0.02857142857142857, 0.11428571428571428, 0.02857142857142857, 0.02857142857142857, \n",
    "    0.02857142857142857, 0.05714285714285714, 0.02857142857142857, 0.02857142857142857, \n",
    "    0.02857142857142857, 0.02857142857142857, 0.05714285714285714, 0.05714285714285714, \n",
    "    0.02857142857142857, 0.02857142857142857, 0.02857142857142857, 0.05714285714285714, \n",
    "    0.05714285714285714, 0.02857142857142857, 0.02857142857142857, 0.02857142857142857, \n",
    "    0.02857142857142857, 0.02857142857142857, 0.02857142857142857]\n",
    "# \text_limits_arr = {'e': 7, 'a': 5, 'i': 4, 'n': 4,\n",
    "# \t 'o': 4, 't': 4, 'l': 3, 's': 3, 'r': 3, 'h': 2,\n",
    "# \t  'f': 2, 'd': 2, 'k': 1, 'g': 1, 'p': 1, 'b': 1,\n",
    "# \t   'c': 1, 'u': 1, 'm': 1, 'w': 1, 'v': 1, 'x': 1, 'y': 1}\n",
    "\n",
    "\tlength = len(ext_ord)\n",
    "\text_limits_arr = get_ext_limit_arr(length, letter, freq_perc)\n",
    "\n",
    "\ths, ht = ((),) , []\n",
    "\n",
    "\t# --------------------------------\n",
    "\t#\t\n",
    "\t# ext_ord = list(ext_ord)\n",
    "\t# taken = []\n",
    "\t# weight_matrix = [1,1,1,1,4,5]\n",
    "\t# --------------------------------\t\n",
    "\n",
    "\tfor card in tqdm(range(length)):\n",
    "\n",
    "\t# --------------------------------\t\n",
    "\t#\n",
    "\t\t# f = ext_ord[0] #if len(ext_ord) >1 else ext_ord[0] \n",
    "\t\t# taken.append(f)\n",
    "\t\t# ext_ord.remove(f)\n",
    "\n",
    "\t# --------------------------------\t\n",
    "\t\t\n",
    "\t\tf = ext_ord[card]\n",
    "\t# --------------------------------\t\n",
    "\t\tfor h in hs: \n",
    "\t\t\tfor e in letter:\n",
    "\t\t\t\tif h == ():\n",
    "\t\t\t\t\tht.append((( e, f ),)) \n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\th_ = h + (( e, f ),)\n",
    "\t\t\t\t\tif ext_limits != 0:\n",
    "\t\t\t\t\t\tif not checkLimit(h_, ext_limits):\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif not checkLimit_arr(h_, ext_limits_arr):\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\tht.append( h_ ) \n",
    "\t\ths, _ = prune(cipher_clean, ht, beam_size)\n",
    "\t\tht = []\n",
    "\t\t# print(hs)\n",
    "\n",
    "\t# --------------------------------\t\n",
    "\t#\n",
    "\t\t# current_sum = 0\n",
    "\t\t# sum_max = 0\n",
    "\t\t# for c in ext_ord:\n",
    "\t\t# \tcurrent_sum = sum_of_weight(cipher, weight_matrix, taken, c)\n",
    "\t\t# \tif current_sum >= sum_max:\n",
    "\t\t# \t\tf = c\n",
    "\t\t# \t\tsum_max = current_sum\n",
    "\t# --------------------------------\t\n",
    "\n",
    "\ths, score = prune(cipher_clean, hs, beam_size, nlm)\n",
    "\n",
    "\tprint('score:',score)\n",
    "\tpp.pprint(hs[0])\n",
    "\tdict = readHypo(hs[0])\n",
    "\tdec = decipher(cipher, dict)\n",
    "\tprint(dec)\n",
    "\t#checkAnswer(answer, dec)\n",
    "\n",
    "# =============================================\n",
    "# main\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tlm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=False)\n",
    "\n",
    "\t# cipher = 'INTERNATIONALSTUDENTSOCIETY'\n",
    "\tcipher = 'F7EZ5F UC2'\n",
    "\tcipher = 'efgfoe uif fbtu xbmm pg uif dbtumf'\n",
    "\tcipher = 'F7EZ5F UC2 1DR6 M9PP 0E 6CZ SD4UP1'\n",
    "\t# cipher = 'RIHILKHIERSKILEKKLKTRSKHRIHILKHLREIRTRSKLKTRSKHHLEKRS'\n",
    "\tcipher = read_file(\"data/cipher.txt\")\n",
    "\n",
    "\tanswer = 'data/_ref.txt'\n",
    "\t# answer = 'data/answer.txt'\n",
    "\t\n",
    "\text_limits = 1 # 0 for using limit_arr\n",
    "\tbeam_size = 3000\n",
    "\tnlm = False\n",
    "\text_ord_dynamic = True\n",
    "\n",
    "\tif nlm: \n",
    "\t\tnLM = load_model(\"data/mlstm_ns.pt\", cuda=True)\n",
    "\tbeamSearch(cipher, beam_size, ext_limits, answer, nlm)\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# =============================================\n",
    "# ============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
